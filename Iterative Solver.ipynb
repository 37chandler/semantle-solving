{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fc3019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from scipy.spatial.distance import cdist \n",
    "from sklearn.preprocessing import normalize\n",
    "from gensim import models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b20a6b",
   "metadata": {},
   "source": [
    "## Load in the language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28798d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = models.KeyedVectors.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f78699",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_ascii = re.compile(r\"^[a-z]+$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f84e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = w2v.index_to_key\n",
    "\n",
    "# semantle uses only lowercase ascii\n",
    "words = [w for w in words if lower_ascii.match(w)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd31f838",
   "metadata": {},
   "source": [
    "Now we create a matrix of all the word vectors that go with these words and we'll renormalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84ba7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = []\n",
    "\n",
    "for word in words : \n",
    "    vecs.append(w2v[word])\n",
    "\n",
    "vec_mat = np.vstack(vecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2289a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_mat = normalize(vec_mat,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2330de",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8c2ad",
   "metadata": {},
   "source": [
    "## Work with distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c745aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both of these functions build off of this: https://github.com/manimino/semantle-crab/blob/main/notebooks/crab.ipynb\n",
    "# which has the correct semantle distance function\n",
    "\n",
    "def get_all_dists(target,word_list, matrix):\n",
    "    idx = word_list.index(target)\n",
    "    vec = np.array([matrix[idx, :]])\n",
    "    dists = cdist(vec, matrix, metric='cosine')\n",
    "    semantle_scores = np.round((1-dists)*100, 1)[0]\n",
    "    score_list = semantle_scores.tolist()\n",
    "    return score_list\n",
    "\n",
    "\n",
    "def pair_dist(word_1, word_2 ,word_list, matrix):\n",
    "    idx_1 = word_list.index(word_1)\n",
    "    idx_2 = word_list.index(word_2)\n",
    "    vec_1 = np.array([matrix[idx_1, :]])\n",
    "    vec_2 = np.array([matrix[idx_2, :]])\n",
    "    dist = cdist(vec_1, vec_2, metric='cosine')\n",
    "    semantle_score = np.round((1-dist)*100, 1)[0].tolist()\n",
    "    return semantle_score[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2c7df1",
   "metadata": {},
   "source": [
    "Feel free to play around with distances and pairs here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f5e9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_all_dists(\"airplane\",words,vec_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_dist(\"airplane\",\"fighter\",words,vec_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c2f6f7",
   "metadata": {},
   "source": [
    "## Guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ac275",
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = \"help\"\n",
    "score = 11.08"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d354ff34",
   "metadata": {},
   "source": [
    "Let's iterate through the words and get all the words that are at this distance from the first guess. Set `tolerance` so that you have a couple hundred suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd31f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = get_dists(guess,words,vec_mat)\n",
    "tolerance = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b9be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestions = dict()\n",
    "\n",
    "for idx, dist in enumerate(distances) : \n",
    "    if np.abs(dist - score) < tolerance : \n",
    "        suggestions[words[idx]] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6d283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(suggestions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a07ca2",
   "metadata": {},
   "source": [
    "Now that we have suggestions, let's find a few different guesses to try. We'll randomly pick a few words from the \"cone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f79f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_suggestions = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c436931",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in list(random.choices(list(suggestions.keys()),k=num_suggestions)) : \n",
    "    print(f\"Try {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae00f38",
   "metadata": {},
   "source": [
    "Now take your best-scoring guess and repeat. We'll write a function to help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab1c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suggestions(word, score, num_suggestions=3,tolerance=0.02,word_list=words,matrix=vec_mat) : \n",
    "    distances = get_all_dists(word,word_list,matrix)\n",
    "    suggestions = dict()\n",
    "\n",
    "    for idx, dist in enumerate(distances) : \n",
    "        if np.abs(dist - score) < tolerance : \n",
    "            suggestions[words[idx]] = dist\n",
    "            \n",
    "            \n",
    "    for word in list(random.choices(list(suggestions.keys()),k=num_suggestions)) : \n",
    "        print(f\"Try {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f580116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_suggestions(\"fracture\",31.81,num_suggestions=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3798cc5b",
   "metadata": {},
   "source": [
    "Iterate and see if you can get there!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
